## 21. 偏差（Bias）和方差（variance）的例子

考虑我们的猫分类任务。一个“理想”的分类器（如人类）在这项任务中可能会取得近乎完美的表现。

假设你的算法表现如下：

- 训练错误率=1%
- 开发错误率=11%

它有什么问题呢？应用我们前一章的定义，我们估计偏差是1%，方差为10%（=11%-1%）。因此，它有**很高的方差（high Variance）**。分类器的训练错误率非常低，但未能推广到开发集。这也被称为过拟合（overfitting）。

现在考虑一下这个：

- 训练错误率=15%
- 开发错误率=16%

我们估计偏差是15%，方差是1%。这分类器适应训练集非常差，错误率为15%，但它在开发集上的错误几乎没有比训练集错误率更高。

因此这个算法具有**很高的偏差（high Bias）**，但是方差较小，我们说这个算法是**欠拟合（underfitting）**。

现在，考虑一下这个：

- 训练错误率=15%
- 开发错误率=30%

我们估计偏差是15%，方差是15%。该分类器具有**较高的偏差和较高的方差（High Bias and High Variance）**：训练集效果较差，因此偏差较大，其在开发集上的效果更差，因此偏差也较大。由于分类器的原因，过拟合/欠拟合这类术语很难应用，它几乎同时过拟合和过拟合。

最后，考虑一下：

- 训练错误率=0.5%
- 开发错误率=1%

这个分类器做的很好，因为它具有低偏差和低方差。恭喜你取得这么大的成就！






